{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a0f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # 使用GPU 0\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering, Birch\n",
    "import csv\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from utils.LNL_DOH import Data_Process\n",
    "from utils.CNN_AE_updated import CNN_AE_Classifier\n",
    "from utils.model_MoCo import MoCo\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f793257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from geomloss import SamplesLoss\n",
    "\n",
    "class SoftClusteringWassersteinLoss(nn.Module):\n",
    "    def __init__(self, num_clusters, feature_dim):\n",
    "        super(SoftClusteringWassersteinLoss, self).__init__()\n",
    "        self.num_clusters = num_clusters\n",
    "        self.centroids = nn.Parameter(torch.randn(num_clusters, feature_dim))\n",
    "        self.wasserstein_loss = SamplesLoss(\"sinkhorn\", p=2, blur=0.01)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        if self.centroids.device != features.device:\n",
    "            self.centroids.data = self.centroids.data.to(features.device)\n",
    "        \n",
    "        batch_size = features.size(0)\n",
    "        \n",
    "        # 计算每个样本到每个中心的距离\n",
    "        distances = torch.cdist(features, self.centroids)\n",
    "        \n",
    "        # 软分配（使用softmax）\n",
    "        soft_assignments = F.softmax(-distances, dim=1)\n",
    "        \n",
    "        # 计算簇内损失（希望最小化）\n",
    "        intra_cluster_loss = torch.mean(torch.sum(soft_assignments * distances, dim=1))\n",
    "        \n",
    "        # 计算簇间损失（希望最大化）\n",
    "        inter_cluster_loss = 0\n",
    "        for i in range(self.num_clusters):\n",
    "            for j in range(i+1, self.num_clusters):\n",
    "                cluster_i = features[soft_assignments[:, i] > 0.5]\n",
    "                cluster_j = features[soft_assignments[:, j] > 0.5]\n",
    "                if len(cluster_i) > 0 and len(cluster_j) > 0:\n",
    "                    w_distance = self.wasserstein_loss(cluster_i, cluster_j)\n",
    "                    inter_cluster_loss -= w_distance\n",
    "        \n",
    "        # 总损失\n",
    "        total_loss = intra_cluster_loss + inter_cluster_loss\n",
    "        \n",
    "        return total_loss, soft_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54e9a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(algorithm = 'TRACE',\n",
    "              dataset = 'DOH',\n",
    "              data = \"./Malicious_TLS/DOH21_new.csv\",\n",
    "              \n",
    "              savedir = './results',\n",
    "              noise_pattern = 'sym', ##asym or sym\n",
    "              INCV_C_list = [0.5],\n",
    "              percent = 0.7,\n",
    "              #seed = 1,\n",
    "              \n",
    "              batch_size = 256, \n",
    "              num_workers =1,\n",
    "              epochs = 100,\n",
    "              adjust_lr = 1,\n",
    "              learning_rate = 1e-2,\n",
    "              \n",
    "              embedding_size = 128,\n",
    "              moco_queue = 8192,\n",
    "              moco_m = 0.999,\n",
    "              temperature = 0.1,\n",
    "              alpha = 0.5,\n",
    "              pseudo_th = 0.8,\n",
    "              proto_m = 0.999,\n",
    "              lr = 0.05,\n",
    "              cos = False,\n",
    "              schedule = [40, 80],\n",
    "              w_proto = 1,\n",
    "              w_inst = 1,\n",
    "              print_freq = 300,\n",
    "              \n",
    "                          \n",
    "              \n",
    "              num_class = 2, #\n",
    "              low_dim = 16,\n",
    "              train_size = 0,\n",
    "              val_size = 0,\n",
    "              input_dim = 120,\n",
    "              \n",
    "              \n",
    "              \n",
    "              ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487d0e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "def adjust_learning_rate(optimizer, epoch, config):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    lr = config['lr']\n",
    "    if config['cos']:  # cosine lr schedule\n",
    "        lr *= 0.5 * (1. + math.cos(math.pi * epoch / config['epochs']))\n",
    "    else:  # stepwise lr schedule\n",
    "        for milestone in config['schedule']:\n",
    "            lr *= 0.1 if epoch >= milestone else 1.\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'    \n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res  \n",
    "    \n",
    "def acc_and_f1(y_true, y_pred, num_cluster, csv_path):\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    y_pred = y_pred.astype(np.int64)\n",
    "    assert y_pred.size == y_true.size\n",
    "\n",
    "    w = np.zeros((num_cluster, num_cluster))\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "\n",
    "    ind = linear_sum_assignment(w.max() - w)\n",
    "    ind = np.array(ind).T\n",
    "\n",
    "    accuracy = 0.0\n",
    "    for i, j in ind:\n",
    "        accuracy += w[i, j]\n",
    "    accuracy /= y_pred.size\n",
    "\n",
    "    # 创建一个新的对齐后的预测标签数组\n",
    "    new_y_pred = np.zeros_like(y_pred)\n",
    "    for i, j in ind:\n",
    "        new_y_pred[y_pred == i] = j\n",
    "\n",
    "    # 计算分类报告\n",
    "    report1 = classification_report(y_true, new_y_pred, digits=4)\n",
    "    report = classification_report(y_true, new_y_pred, digits=4, output_dict=True)\n",
    "\n",
    "    return accuracy, report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c829a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def TRACE():\n",
    "    csv_filename = f\"{config['num_class']}_{config['dataset']}_{config['noise_pattern']}_{str(INCV_c)}_attentionAE_was.csv\"\n",
    "    cls_acc = []\n",
    "    KMeans_acc = []\n",
    "    \n",
    "    data = pd.read_csv(config['data'])\n",
    "    class_le = LabelEncoder()\n",
    "    data['Label'] = class_le.fit_transform(data['Label'])\n",
    "    df_train = data.sample(frac = config['percent'])  \n",
    "    df_val = data[~data.index.isin(df_train.index)]  \n",
    "    \n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_val = df_val.reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = Data_Process(data = df_train,\n",
    "                               train=True,\n",
    "                               transform = transforms.ToTensor(),\n",
    "                               noise_type = config['noise_pattern'],\n",
    "                               INCV_b = INCV_b,\n",
    "                               INCV_c = INCV_c             \n",
    "                               )\n",
    "        \n",
    "    val_dataset = Data_Process(data = df_val,#\n",
    "                               train=False,\n",
    "                               transform = transforms.ToTensor(),\n",
    "                               noise_type = config['noise_pattern'],\n",
    "                               INCV_b = INCV_b,\n",
    "                               INCV_c = INCV_c             \n",
    "                               )\n",
    "    \n",
    "    config['train_size'] = len(train_dataset)\n",
    "    config['val_size'] = len(val_dataset)\n",
    "    config['num_class'] = len(np.unique(data['Label']))\n",
    "    config['input_dim'] = 120\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=config['batch_size'], \n",
    "                                               num_workers=config['num_workers'],\n",
    "                                               drop_last=True,\n",
    "                                               shuffle=True)\n",
    "        \n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                              batch_size=config['batch_size'], \n",
    "                                              num_workers=config['num_workers'],\n",
    "                                              drop_last=True,\n",
    "                                              shuffle=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################################################\n",
    "    \n",
    "    print('building model...')\n",
    "    \n",
    "    model = MoCo(CNN_AE_Classifier,config)\n",
    "    model.cuda()\n",
    "    \n",
    "    criterion2 = nn.CrossEntropyLoss()#.cuda()\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = config['lr'],\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-4)\n",
    "    \n",
    "    for epoch in range(1,config['epochs']):\n",
    "        print('epoch:',epoch)\n",
    "           \n",
    "        adjust_learning_rate(optimizer, epoch, config)\n",
    "        \n",
    "        \n",
    "        batch_time = AverageMeter('Time', ':1.2f')\n",
    "        data_time = AverageMeter('Data', ':1.2f')   \n",
    "        acc_cls = AverageMeter('Acc@Cls', ':2.2f')\n",
    "        acc_proto = AverageMeter('Acc@Proto', ':2.2f')\n",
    "        #acc_inst = AverageMeter('Acc@Inst', ':2.2f')\n",
    "        \n",
    "        progress = ProgressMeter(\n",
    "            len(train_loader),\n",
    "            [batch_time, data_time, acc_cls, acc_proto],\n",
    "            prefix=\"Epoch: [{}]\".format(epoch))\n",
    "        \n",
    "        ##开始训练\n",
    "        model.train()\n",
    "        end = time.time()\n",
    "        \n",
    "        for i, (x, target_, indexes) in enumerate(train_loader):\n",
    "            # print(x.shape)\n",
    "            x = x.reshape(config['batch_size'],1,-1)\n",
    "            x = Variable(x).cuda()\n",
    "            # x_aug = x_aug.reshape(config['batch_size'],1,-1)\n",
    "            # x_aug = Variable(x_aug).cuda()\n",
    "            # print(x.shape)\n",
    "            target_ = Variable(target_).cuda()\n",
    "            \n",
    "            data_time.update(time.time() - end)\n",
    "            \n",
    "            loss = 0\n",
    "            \n",
    "            # compute model output               \n",
    "            cls_out, target, logits, x_q, logits_proto, u = \\\n",
    "            model(x, target_, config, is_eval=False, is_proto=(epoch>0))       \n",
    "                \n",
    "            loss_proto = criterion2(logits_proto, target.squeeze(1))\n",
    "            acc = accuracy(logits_proto, target)[0] \n",
    "            acc_proto.update(acc[0]) \n",
    "            \n",
    "            loss_cls = criterion2(cls_out, target.squeeze(1)) \n",
    "            soft_clustering_loss = SoftClusteringWassersteinLoss(num_clusters=23, feature_dim=128)\n",
    "            soft_clustering_loss = soft_clustering_loss.to(u.device)\n",
    "            loss_war, assignments = soft_clustering_loss(u)\n",
    "            loss_AE = nn.MSELoss()(x, x_q)\n",
    "            x_1 = x.reshape(config['batch_size'],-1)\n",
    "            loss = loss_cls + config['w_proto']*loss_proto + loss_AE + loss_war\n",
    "            \n",
    "            # log accuracy\n",
    "            acc = accuracy(cls_out, target)[0] \n",
    "            acc_cls.update(acc[0])\n",
    "               \n",
    "             \n",
    "            # compute gradient and do SGD step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()#######\n",
    "            optimizer.step()\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            #if i % config['print_freq'] == 0:\n",
    "                #progress.display(i)\n",
    "         \n",
    "        with torch.no_grad():\n",
    "            print('==> Evaluation...')       \n",
    "            model.eval()    \n",
    "            top1_acc = AverageMeter(\"Top1\")\n",
    "            top5_acc = AverageMeter(\"Top5\")\n",
    "\n",
    "            all_preds = []\n",
    "            all_targets = []\n",
    "            \n",
    "            # evaluate on webvision val set\n",
    "            for batch_idx, (x, target_, indexes) in enumerate(val_loader):\n",
    "                x = x.reshape(config['batch_size'],1,-1)\n",
    "                x = Variable(x).cuda()\n",
    "                target_ = Variable(target_).cuda()\n",
    "                                \n",
    "                outputs,_,target = model(x, target_, config, is_eval=True)    \n",
    "                acc1 = accuracy(outputs, target)\n",
    "                top1_acc.update(acc1[0])\n",
    "\n",
    "                # Store predictions and targets for later use\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                            \n",
    "            # average across all processes\n",
    "            acc_tensors = torch.Tensor([top1_acc.avg]).cuda()\n",
    "            # Convert lists to numpy arrays\n",
    "            all_preds = np.array(all_preds)\n",
    "            all_targets = np.array(all_targets)\n",
    "            \n",
    "            # Compute classification report\n",
    "            class_names = [f\"Class {i}\" for i in range(config['num_class'])]  # Adjust this if you have actual class names\n",
    "            report = classification_report(all_targets, all_preds, target_names=class_names, digits=4)\n",
    "            # Compute macro-averaged metrics\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_preds, average='macro')\n",
    "            \n",
    "            # average across all processes\n",
    "            acc_tensor = torch.Tensor([top1_acc.avg]).cuda()\n",
    "           \n",
    "            val_ACC = KMeans_model_evaluation(model = model, train_dataloader= train_loader, val_dataloader = val_loader)\n",
    "\n",
    "        cls_acc.append(acc_tensors[0].data.cpu().numpy())\n",
    "        KMeans_acc.append(val_ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ede564",
   "metadata": {},
   "outputs": [],
   "source": [
    "for INCV_c in config['INCV_C_list']:\n",
    "    #INCV_c = 0.9\n",
    "    if config['noise_pattern'] == 'asym':\n",
    "        INCV_b = 0 \n",
    "    else:\n",
    "        INCV_b = INCV_c\n",
    "    \n",
    "    print(\"INCV_c:\",INCV_c)\n",
    "    TRACE()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
